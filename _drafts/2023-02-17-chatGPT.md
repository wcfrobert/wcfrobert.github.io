---
layout: blog-post
categories: blog
title: "Writing is Thinking"
description: "Je vais essayer"
image: assets/img/blog/chatGPT.png
date: 2023-02-17
tags: thoughts
---



## The Danger of ChatGPT

With all of that as preface, let's move on to the topic that's been generating a lot of buzz in the media lately: ChatGPT. Specifically, I want to talk about it in the context of writing.

<img src="/assets/img/blog/chatGPT1.png" style="width:70%;"/> 
*Excerpt From Yann Lecunn's Linkedin Post on Large Language Models like ChatGPT*

The snip above is from a viral LinkedIn post from world-renowned AI researcher Yann Lecunn. In the post, he is evidently trying to curb the recent hype in LLMs, and to downplay the perceived utility of ChatGPT. But the one thing he does not downplay is how ChatGPT could be useful as "a writing aid".

In case you've never used ChatGPT before, it works like this: you give the AI your main arguments in bullet point form, then the AI is capable of generating proses, paragraphs, to entire essays in any style you want within seconds. You can write a short story, a haiku, a Shakespearean sonnet, a piece of investigative journalism, a high school book report, a business email, anything your heart desires. If you don't like the first generated draft, you can keep "chatting" with the AI to continually refine what was written previously. With this tool, you can conceivably write an essay on incredibly complex topics like a dissection of Simone De Beauvoir's Ethics of Ambiguity in minutes, rather than hours plus however long it took to do your research - that is if you didn't use ChatGPT to do your research in the first place.

I am not worried in the "AI will take my job" kind of way, nor in the "I am a luddite and I oppose all change" kind of way. I am worried because these tools are just too fucking good. They have the potential to fundamentally change <u>how</u> we think and by extension what it means to be human. 

The universal theme technological advancements is reducing our physical/cognitive load and the drudgeries therein so we can "focus on more interesting things". But nothing cuts quite as deep and as wide as the large language model. What happens if we reduce the need to <u>think</u> itself? Writing (and by extension thinking) comes in two parts: the generation of ideas, and the organization of jumbled thoughts into something more coherent and structured. Is the second step really inconsequential enough to be skipped? Maybe it is just more efficient to communicate in bullet point form. Maybe our current means of communication is too high latency anyways. I really don't know. How long until we needn't think at all? Will our public discourse eventually happen in bullet point form too? As imprecise and disorganized stream of thoughts with a 280 character limit? Like the inconsequential chirp of birds? Wait ....

Another concern I have about these tools is how easy and low friction they make it for students to cheat. When I was in college, I occasionally get ads for essay-writing services on social media. I've always found those ads to embody the utter degradation of our education system and misalignment of priorities. During our four years of college, our sole purpose in life is to learn, to think, and to learn to think. How ridiculously counter-productive it is to forego the only responsibility you have at that age and nerf yourself? Why spend money to guarantee a direct path to mediocrity. But we live in the age of LLMs now, a student can press a few keystrokes and have an entire essay written for them, for free, in seconds. I don't think I would have been able to handle that kind of temptation in my foolish youth (even more than now). <u>But here is the real conundrum</u>: Notwithstanding the moral and pedagogical arguments, from a purely practical standpoint, is it really "cheating"? Sure, their understanding of the underlying theory of some subject matter will be hampered, but students will most certainly have access to these tools when they enter the workplace. Those who can effectively leverage LLMs will surely be more efficient than those who can't. This is such a galactic size paradigm shift. How do I even begin to think about this?

I prefer to think of myself as a technologist and the quintessential early adopter/tinkerer. The recent advancement in AI is nothing short of amazing! I am constantly blown away by the quality (and dare I say creativity) of arts generated by tools like DALL.E and midjourney. And I hardly need to express how breathtaking ChatGPT is. I'm sure these tools will provide productivity boost on a level we can't yet comprehend. If this is really just the beginning of an AI explosion, then we are surely headed towards an exciting albeit turbulent decade. Yet when I think of the concurrent explosion of online misinformation, and our already frayed public discourse, my excitement quickly turns into unease.

---

*Disclaimer: This blog post was written without the use of ChatGPT nor any other LLMs. I don't think I ever will, at least for these blog posts. That would be utterly counter-productive. It would be like running on the treadmill while eating a big mac. I would certainly lose more than I gain. (I guess in the context of this analogy, I would gain more than I lose... Anyways, you get the point)*
