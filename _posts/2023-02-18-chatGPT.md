---
layout: blog-post
categories: blog
title: "ChatGPT"
description: "The danger of letting AIs think for us"
image: assets/img/blog/chatGPT.png
date: 2023-02-18
tags: thoughts
---

<img src="/assets/img/blog/chatGPT1.png" style="width:70%;"/> 
*Excerpt From Yann Lecunn's Linkedin Post on Large Language Models like ChatGPT*

The snip above is from a viral LinkedIn post from world-renowned AI researcher Yann Lecunn. He is evidently trying to curb the recent hype in LLMs, and to downplay the perceived utility of ChatGPT. But the one thing he does not downplay is how ChatGPT could be useful as "a writing aid".

In my last post, I wrote about how the process of writing is entirely analogous to thinking; that becoming proficient in one transfer well to the other. In this blog post, I want to explore the topic of ChatGPT in the context of writing.

In case you've never used ChatGPT before, it works like this: you give the AI your main arguments in bullet point form, then the AI is capable of generating proses, paragraphs, to entire essays in any style, in mere seconds. You can write a short story, a haiku, a Shakespearean sonnet, a piece of investigative journalism, a high school book report, a business email, anything your heart desires. If you don't like the first generated draft, you can keep "chatting" with the AI to continually refine what was written previously. With this tool, you can conceivably write an essay on incredibly complex topics in minutes, rather than hours plus however long it took to do your research - that is if you didn't use ChatGPT to do your research in the first place.

I'm sure you are well-aware of the mind-blowing capabilities of these LLMs; the internet is filled with them. But if we look beyond the initial excitement and its immeasurable potential:

* Could the use of these AI tools atrophy our ability to think? 
* What would education look like in the presence of these AI tools?

The universal theme technological advancements is reducing our physical/cognitive load and the drudgeries therein so we can "focus on more interesting things". But nothing cuts quite as deep and as wide as the large language model. What happens if we reduce the need to <u>think</u> itself? Writing - and by extension thinking - comes in two parts: the generation of ideas, and the organization of jumbled thoughts into something more coherent and structured. Is the second step really inconsequential? Maybe it is just more efficient to communicate in bullet point form (like what Dr. Lecunn doing above). Maybe our current means of communication is too high latency. I really don't know. How long until we needn't think at all? Will our public discourse eventually happen in bullet point form too? As imprecise and disorganized stream of thoughts with a 280 character limit? Like the inconsequential chirp of birds? How will our critical thinking skills be hampered by AI in the midst of an explosion of online misinformation?

Another concern I have about these tools is how easy and low friction they make it for students to cheat. When I was in college, I occasionally get ads for essay-writing services on social media. I've always found those ads to embody the utter degradation of our education system and misalignment of priorities. During college, our main purpose in life is to learn, to think, and to learn to think. How ridiculously counter-productive it is to forego the most important responsibility you have at that age and nerf yourself? Why spend money to guarantee a direct path to mediocrity. But we live in the age of LLMs now, a student can press a few keystrokes and have an entire essay written for them, for free, in seconds. I don't think I would have been able to handle that kind of temptation in my youth. But here is the real conundrum: Notwithstanding the moral and pedagogical arguments, from a purely economical standpoint, is it really "cheating"? Sure, their understanding of the underlying theory of some subject matter will be hampered, but students will most certainly have access to these tools when they enter the workplace. You don't have to understand how a calculator works to use it. Those who can effectively leverage LLMs will surely be more efficient than those who can't.

I prefer to think of myself as a technologist and the quintessential early adopter/tinkerer. The recent advancement in AI is nothing short of amazing! I am constantly blown away by the quality (and dare I say creativity) of arts generated by tools like DALL.E and midjourney. And I hardly need to express how breathtaking ChatGPT is. I'm sure these tools will provide productivity boost on a level we can't yet comprehend. If this is really just the beginning of an AI explosion, then we are surely headed towards an exciting albeit turbulent decade. Yet when I think of the concurrent explosion of online misinformation, and our already frayed public discourse, my excitement quickly turns into unease.

---

*Disclaimer: This blog post was written without the use of ChatGPT nor any other LLMs. I never will, at least for these blog posts. That would be utterly counter-productive. Like running on the treadmill while eating a big mac, I would certainly lose more than I gain. (I guess in the context of this analogy, I would gain more than I lose... Anyways, you get the point)*
