---
layout: blog-post
categories: blog
title: "Letting AIs Think For Us"
description: "Thoughts on ChatGPT in the context of writing"
image: assets/img/blog/chatGPT.png
date: 2023-02-18
tags: thoughts
---

## Letting AIs Think For Us

<img src="/assets/img/blog/chatGPT1.png" style="width:70%;"/> 
*Excerpt From Yann Lecunn's Linkedin Post on Large Language Models like ChatGPT*

The snip above is from a viral LinkedIn post from world-renowned AI researcher Yann Lecunn. Given the recent hype around large language models (LLMs), he is evidently trying to curb the excitement and downplay the perceived utility of ChatGPT. However, the one thing he does not downplay is how ChatGPT could be "a useful writing aid". In my last post, I wrote about how the process of writing is entirely analogous to thinking; that becoming a good writer has the added benefit of improving your critical thinking skills as well. In this blog post, I want to explore the topic of ChatGPT in the context of writing.

In case you've never used ChatGPT before, it works like this: you give the AI your main arguments in bullet point form, then the AI is capable of generating proses, paragraphs, to entire essays in any style in mere seconds. You can write a short story, a haiku, a Shakespearean sonnet, a piece of investigative journalism, a high school book report, a business email. If you are feeling bored, you can even ask it to write anything in an abecedarian verse - where the first line begins with A, second with B, third with C, all the way through the alphabet. [It will do it better than any human can, with awe-inspiring creativity, in seconds...](https://www.nytimes.com/2023/03/21/opinion/artificial-intelligence-chatgpt.html) If you don't like the first generated draft, you can keep "chatting" with the AI to continually refine what was written previously. With this tool, you can conceivably write an essay on incredibly complex topics in minutes, rather than hours plus however long it took to do your research - that is if you didn't use ChatGPT to do your research in the first place.

The universal theme of all past technological advancements has been to reduce our physical/cognitive load and the mundane drudgeries so we can "focus our time on more interesting things". <u>But is there anything that cuts as deep and as wide as large language models</u>. What happens if we reduce the need to think itself? 

Writing - and by extension thinking - comes in two parts: the generation of ideas, and the organization of jumbled thoughts into something more coherent and structured; ideally in well-written proses that are grammatically correct. Is the second step really unnecessary? Perhaps it's just more efficient to communicate in bullet point form like what Dr. Lecunn is doing in his LinkedIn post. Maybe the latency for our current means of communication is too high. I really don't know. But it's worth thinking about. Will our public discourse eventually happen in bullet point form too? As imprecise and disorganized stream of thoughts with a 280 character limit? Like the inconsequential chirp of birds? 

As these AI tools evolve and get better in the coming years, how long until we needn't think at all? When AIs can do the thinking for us, or most of it, do we lose the capacity to research and think for ourself? Will it make us intellectually lazy and easy to manipulate? Will it atrophy our critical thinking muscles at the exact point in history when we need it most to navigate the explosion of online misinformation?

## The Perfect Cheating Tool

Another concern I have about these tools is how easy and low friction they make it for students to cheat. When I was in college, I occasionally received ads for essay-writing services on social media. I've always found them to be quite distasteful and exploitative. The main purpose of a college education is to learn, to think, and to learn to think. If you are tempted to purchase these services, just remind yourself this: how ridiculously counter-productive to forego the most important responsibility you have at that age? Why spend money to guarantee a direct path to mediocrity? 

But we live in the age of LLMs now, a student can press a few keystrokes and have an entire essay written for them, for free, in seconds. It can answer most problem-set questions, and ace take-home exams with flying colors. I don't think I would have been able to handle that kind of temptation in my youth. But here is the real conundrum: Notwithstanding the moral and pedagogical arguments, from a purely economical standpoint, is it really "cheating"? Sure, their understanding of the underlying theory of some subject matter will be hampered, but students will most certainly have access to these tools when they enter the workplace. You don't have to understand how a calculator works to use it. Those who can effectively leverage LLMs will surely be more efficient than those who can't.

I prefer to think of myself as a technologist and the quintessential early adopter/tinkerer. The recent advancement in AI is nothing short of amazing! I am constantly blown away by the quality (and dare I say creativity) of arts generated by tools like DALL.E and midjourney. And I hardly need to express how breathtaking ChatGPT is. I'm sure these tools will provide productivity boost on a level we can't yet comprehend. If this is really just the beginning of an AI explosion, then we are surely headed towards an exciting albeit turbulent decade. Yet when I think of the concurrent explosion of online misinformation, and our already frayed public discourse, my excitement quickly turns into unease.

---

*Disclaimer: This blog post was written without the use of ChatGPT nor any other LLMs. It wouldn't make sense for me to use them for these blog posts. That would be utterly counter-productive; like running on the treadmill while eating a big mac, I would certainly lose more than I gain. (I guess in the context of this analogy, I would gain more than I lose... Anyways, you get the point)*
